import streamlit as st
from utils import (
    load_faq,
    generate_embeddings,
    create_faiss_index,
    search_faq,
    initialize_langchain_model,
    generate_faq_response
)
import os
from dotenv import load_dotenv

# D√©finir TOKENIZERS_PARALLELISM pour √©viter les avertissements
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# Charger les variables d'environnement depuis le fichier .env
load_dotenv()

# R√©cup√©rer la cl√© API OpenAI depuis les variables d'environnement via secrets
# Note : Ne pas utiliser os.getenv directement pour les secrets sur Streamlit
# Utilisez st.secrets √† la place
openai_api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else None


# Titre principal de l'application
st.title('ü§ñ Chatbot FAQ Professionnel')

# Champ de saisie pour les questions des utilisateurs
prompt = st.text_input('Posez votre question ‚ùì', key="prompt")

# Bouton de soumission
submit = st.button("Obtenir une R√©ponse")

# Fonction mise en cache pour charger les FAQ
@st.cache_data
def get_faq_data():
    return load_faq()


if submit:
    if openai_api_key:

        # Charger les FAQ (mis en cache)
        faq_data = get_faq_data()
        st.write("Chargement des FAQ termin√©...") # A commenter

        # G√©n√©rer les embeddings
        embeddings, model, dimension = generate_embeddings(faq_data)

        # Cr√©er l'index FAISS
        index, answers = create_faiss_index(embeddings, dimension, faq_data)
        st.write("Index FAISS cr√©√© avec succ√®s...") # A commenter

        # R√©cup√©rer les documents pertinents depuis FAISS
        relavant_docs = search_faq(prompt, index, answers, model, k=2)
        st.write("Documents pertinents trouv√©s :")
        st.write(relavant_docs)

        # Initialiser le mod√®le LangChain avec OpenAI
        llm = initialize_langchain_model(openai_api_key, model_name="gpt-3.5-turbo")  # ou "gpt-4" si disponible
        st.write("Mod√®le de langage initialis√© avec LangChain et OpenAI...")

        # G√©n√©rer la r√©ponse en utilisant le mod√®le de langage avec LangChain
        response = generate_faq_response(relavant_docs, prompt, llm)
        st.success("R√©ponse √† votre question :")
        st.write(response)
    else:
        st.sidebar.error("Ooopssss!!! La cl√© API OpenAI est manquante dans le fichier .env.....")
